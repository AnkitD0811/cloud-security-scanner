# ---------------- Importing Libraries ----------------------

from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import PromptTemplate

from langgraph.graph import StateGraph, START, END

from typing import TypedDict, Literal, List
from pydantic import BaseModel, Field

import json
from dotenv import load_dotenv

# --------------- Load environment variables ------------------

load_dotenv()

# ---------------- Structured output schema -------------------

class SecurityIssue(BaseModel):
    """
    Represents a security issue found in the IaC template.
    """
    issue_name: str = Field(..., description="A concise name for the security issue.")
    severity: Literal['Low', 'Medium', 'High'] = Field(..., description="The severity level, can be either Low, Medium or High.")
    possible_problems: List[str] = Field(..., description="A list of potential problems or risks that could result from this misconfiguration.")
    remedies: List[str] = Field(..., description="A list of actionable steps to fix the issue.")

class SecurityReport(BaseModel):
    """
    The final security report with all identified issues.
    """
    report_title: str = Field(..., description="A title for the security report.")
    summary: str = Field(..., description="A brief summary of the overall security posture.")
    issues: List[SecurityIssue] = Field(..., description="A list of all security issues found in the IaC template.")


# ----------------- Graph State -----------------------

class GraphState(TypedDict):
    """
    Represents the state of the graph.
    """
    iac_template: str
    report: SecurityReport

# LLM to be used

llm = OllamaLLM(model="llama3:8b",
                temperature=0
                )

# ------------------- Prompt Template -------------------

prompt_template = PromptTemplate(
    template="""
    You are an expert in Infrastructure as Code (IaC) security analysis. Your task is to analyze the following IaC template for security misconfigurations and generate a detailed report.

    You must respond with ONLY a valid JSON object that strictly follows this schema:
    {{
        "report_title": "string",
        "summary": "string", 
        "issues": [
            {{
                "issue_name": "string",
                "severity": "High|Medium|Low",
                "possible_problems": ["string1", "string2"],
                "remedies": ["string1", "string2"]
            }}
        ]
    }}

    For each identified issue, you must provide:
    1. A concise name for the issue.
    2. A severity level ('High', 'Medium', 'Low').
    3. A list of possible problems that could arise from the misconfiguration.
    4. A list of actionable remedies to fix the issue.

    If no misconfigurations are found, generate an empty list of issues.

    Here is the IaC template to analyze:
    ```
    {iac_template}
    ```

    Respond with ONLY the JSON object, no additional text:
    """,
    input_variables=["iac_template"],
)


# ------------------ Graph node functions ---------------------
llm_chain = prompt_template | llm

def generate_report(state: GraphState) -> GraphState:
    """
    This node takes the IaC template and generates a security report using the LLM.
    """
    print("Analyzing IaC template and generating report...")
    iac_template = state["iac_template"]
    raw_response = llm_chain.invoke({"iac_template": iac_template})
    print("Report generated.")

    try:
        # Parse the JSON response
        report_dict = json.loads(raw_response)
        
        # Create SecurityReport object from the parsed JSON
        report = SecurityReport(**report_dict)
        print("Report generated.")
        return {"report": report}
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON response: {e}")
        print(f"Raw response: {raw_response}")
        # Return empty report on error
        return {"report": SecurityReport(
            report_title="Analysis Error",
            summary="Failed to parse security analysis results.",
            issues=[]
        )}
    except Exception as e:
        print(f"Error creating SecurityReport: {e}")
        return {"report": SecurityReport(
            report_title="Analysis Error", 
            summary="Failed to create security report.",
            issues=[]
        )}

    return {"report": report}


# Build the LangGraph
graph = StateGraph(GraphState)

# Add the single node to the graph
graph.add_node("generate_report", generate_report)

# Set the entry and exit points for the graph
graph.add_edge(START, "generate_report")
graph.add_edge("generate_report", END)

# Compile the graph into a runnable application
app = graph.compile()

# Trying on a template generated by SadCloud

with open("main.tf", "r") as f:
    tf_string = f.read()

print("\n--- Running analysis on template ---")
initial_state = {"iac_template": tf_string}
final_state = app.invoke(initial_state)

print("\nGenerated Security Report:")
print(json.dumps(final_state["report"].model_dump(), indent=2))

output_filename = "security_report.json"
with open(output_filename, "w") as f:
    json.dump(final_state["report"].model_dump(), f, indent=2)

print(f"\nReport saved to: {output_filename}")